{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "\n",
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomResizedCrop,\n",
    "    Resize,\n",
    "    ToTensor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../dataset\"\n",
    "\n",
    "datasets = load_dataset(\"imagefolder\", data_dir=dataset_path)\n",
    "\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datasets[\"train\"][0])\n",
    "\n",
    "datasets[\"train\"][0]['image']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Preprocessing images typically comes down to (1) resizing them to a particular size (2) normalizing the color channels (R,G,B) using a mean and standard deviation. These are referred to as image transformations.\n",
    "\n",
    "In addition, one typically performs what is called data augmentation during training (like random cropping and flipping) to make the model more robust and achieve higher accuracy. Data augmentation is also a great technique to increase the size of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id, id2label = dict(), dict()\n",
    "for id, label in enumerate(datasets[\"train\"].features[\"label\"].names):\n",
    "    label2id[label] = id\n",
    "    id2label[id] = label\n",
    "\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"microsoft/swin-tiny-patch4-window7-224\"\n",
    "image_processor  = AutoImageProcessor.from_pretrained(model_id)\n",
    "image_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "if \"height\" in image_processor.size:\n",
    "    size = (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    "    crop_size = size\n",
    "    max_size = None\n",
    "elif \"shortest_edge\" in image_processor.size:\n",
    "    size = image_processor.size[\"shortest_edge\"]\n",
    "    crop_size = (size, size)\n",
    "    max_size = image_processor.size.get(\"longest_edge\")\n",
    "\n",
    "train_transforms = Compose(\n",
    "        [\n",
    "            RandomResizedCrop(crop_size),\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "eval_transforms = Compose(\n",
    "        [\n",
    "            Resize(size),\n",
    "            CenterCrop(crop_size),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def preprocess_train(example_batch):\n",
    "    \"\"\"Apply trainuing transformation across a batch.\"\"\"\n",
    "    example_batch[\"pixel_values\"] = [\n",
    "        train_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]\n",
    "    ]\n",
    "    return example_batch\n",
    "\n",
    "def preprocess_eval(example_batch):\n",
    "    \"\"\"Apply evaluation transformations across a batch.\"\"\"\n",
    "    example_batch[\"pixel_values\"] = [eval_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n",
    "    return example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"train\"].set_transform(preprocess_train)\n",
    "datasets[\"validation\"].set_transform(preprocess_eval)\n",
    "datasets[\"test\"].set_transform(preprocess_eval)\n",
    "\n",
    "datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_id, \n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    ignore_mismatched_sizes = True, # provide this in case you're planning to fine-tune an already fine-tuned checkpoint,\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric = load_metric(\"accuracy\", trust_remote_code=True)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=eval_pred.label_ids)\n",
    "\n",
    "def data_collator(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "model_name = model_id.split(\"/\")[-1]\n",
    "batch_size = 32\n",
    "gradient_accumulation_steps = 4\n",
    "num_train_epochs = 5\n",
    "learning_rate = 5e-5\n",
    "warmup_ratio = 0.1\n",
    "logging_steps = 10\n",
    "metric_for_best_model = \"accuracy\"\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    f\"../checkpoints/{model_name}\",\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    #logging_steps=logging_steps,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_for_best_model,\n",
    "    push_to_hub=False,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_arguments,\n",
    "    train_dataset=datasets[\"train\"],\n",
    "    eval_dataset=datasets[\"validation\"],\n",
    "    tokenizer=image_processor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = [\"eval_accuracy\"]\n",
    "validation_evalation_results = trainer.evaluate(datasets[\"validation\"])\n",
    "test_evalation_results = trainer.evaluate(datasets[\"test\"])\n",
    "evaluatation_results = {\n",
    "    \"validation\": {metric_name: round(validation_evalation_results[metric_name] * 100, 2) for metric_name in metric_names},\n",
    "    \"test\": {metric_name: round(test_evalation_results[metric_name] * 100, 2) for metric_name in metric_names}\n",
    "}\n",
    "\n",
    "evaluatation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"../models/{model_name}\"\n",
    "trainer.save_model(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plant-disease-classification-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
